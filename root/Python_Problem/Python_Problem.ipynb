{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Problem\n",
    "\n",
    "### By: Amartya Kalapahar(amartyaandroid@gmail.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy \n",
    "from tweepy import OAuthHandler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'auth = tweepy.OAuthHandler(\"\", \"\")\\nauth.set_access_token(\"\", \"\")\\n\\napi = tweepy.API(auth)\\n\\npublic_tweets = api.home_timeline()\\nfor tweet in public_tweets:\\n    print(tweet.text)'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''auth = tweepy.OAuthHandler(\"\", \"\")\n",
    "auth.set_access_token(\"\", \"\")\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "public_tweets = api.home_timeline()\n",
    "for tweet in public_tweets:\n",
    "    print(tweet.text)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RT @RatnRajiv: @midasIIITD @IIITDelhi @Hitkul_ @_himanshu0113 @ManshulB @himani @BaaniLeen @shagunuppls @gyaneshanand share the words with…', '@midasIIITD lab is looking for motivated MTech @IIITDelhi students who are interested in doing their thesis in #NLP… https://t.co/0MMf7euBVv', 'We will close the submission portal for submitting your internship task mid-night. Kindly submit your solution in t… https://t.co/KLWtGRSxSb', 'Clarification: Our earlier post which indicates that the interview has been done is referring to the interviews of… https://t.co/x8Etf6qEOn', 'RT @IIITDelhi: Applications open for MTech (CB) through JNU CEEB Admission process. Candidates can check the JNU CEEB admission process in…', 'RT @IIITDelhi: We are delighted to share that IIIT-Delhi is ranked 55 by NIRF this year. We have moved up by 11 positions compared to the p…', 'RT @Harvard: Professor Jelani Nelson founded AddisCoder, a program that teaches students in Ethiopia how to code https://t.co/0sM06p4qxw', 'RT @emnlp2019: For anyone interested in submitting to EMNLP 2019, the anonymity period begins in less two weeks, on April 21.\\nhttps://t.co/…', 'RT @multimediaeval: Announcing the 2019 MediaEval multimedia tasks: https://t.co/V6NMt1vaNV Participation is open for anyone who is interes…', 'Many Congratulations to @midasIIITD student, Shagun Uppal @shagunuppls, on getting selected for the summer internsh… https://t.co/bzhiSm4zuB', '@midasIIITD thanks all students who have appeared for the interview yesterday. We will announce the interview resul… https://t.co/qxESgZPtKJ', '@himanchalchandr Meanwhile, complete CV/NLP task first.', '@sayangdipto123 Submit as per the guideline again.', 'We request all students whose interview are scheduled today to join at the time given to them and not before or aft… https://t.co/7cnrlj1b9Q', 'Other queries: \"none of the Tweeter Apis give the correct count of favorites tested for most of them, all give the… https://t.co/2jnCTMMqV8', 'Other queries: \"do we have to make two different repositories on Github as \"Python Problem\" and \"CV Problem\". Or we… https://t.co/45x8RhQcAT', 'Other queries: \"If using Twitter api, it does not include any information about images in the response objects sent… https://t.co/JEWZB2XTPq', 'Response to some queries asked by students on @midasIIITD task.\\nWhat does the line \"dump the responses into JSONlin… https://t.co/Rr6ri8lyVY', 'RT @kdnuggets: Top 8 #Free Must-Read #Books on #DeepLearning #KDN https://t.co/1DtlN91Yjj', '@nupur_baghel @PennDATS Congratulation @nupur_baghel on getting admit from @PennDATS. \\nShe got 5/10 acceptance. She… https://t.co/ooD8yneUwS']\n"
     ]
    }
   ],
   "source": [
    "# Fill the X's with the credentials obtained by  \n",
    "# following the above mentioned procedure. \n",
    "consumer_key = \"\" \n",
    "consumer_secret = \"\"\n",
    "access_key = \"\"\n",
    "access_secret = \"\"\n",
    "  \n",
    "# Function to extract tweets \n",
    "def get_tweets(username): \n",
    "          \n",
    "        # Authorization to consumer key and consumer secret \n",
    "        auth = tweepy.OAuthHandler(consumer_key, consumer_secret) \n",
    "  \n",
    "        # Access to user's access key and access secret \n",
    "        auth.set_access_token(access_key, access_secret) \n",
    "  \n",
    "        # Calling api \n",
    "        api = tweepy.API(auth) \n",
    "  \n",
    "        # 200 tweets to be extracted \n",
    "        number_of_tweets=2\n",
    "        tweets = api.user_timeline(screen_name=username) \n",
    "  \n",
    "        # Empty Array \n",
    "        tmp=[]  \n",
    "  \n",
    "        # create array of tweet information: username,  \n",
    "        # tweet id, date/time, text \n",
    "        tweets_for_csv = [tweet.text for tweet in tweets] # CSV file created  \n",
    "        for j in tweets_for_csv: \n",
    "  \n",
    "            # Appending tweets to the empty array tmp \n",
    "            tmp.append(j)  \n",
    "  \n",
    "        # Printing the tweets \n",
    "        return tmp\n",
    "  \n",
    "  \n",
    "# Driver code \n",
    "if __name__ == '__main__': \n",
    "  \n",
    "    # Here goes the twitter handle for the user \n",
    "    # whose tweets are to be extracted. \n",
    "    #str_tweet = []\n",
    "    str_tweet=get_tweets(\"midasIIITD\")\n",
    "    \n",
    "    print(str_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a method from the above code\n",
    "# Authorization to consumer key and consumer secret \n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret) \n",
    "\n",
    "# Access to user's access key and access secret \n",
    "auth.set_access_token(access_key, access_secret) \n",
    "\n",
    "# Calling api \n",
    "api = tweepy.API(auth) \n",
    "\n",
    "def get_tweetss(username, api):\n",
    "  \n",
    "    alltweets = [] # a list to hold all the Tweets\n",
    "\n",
    "    # request for most recent tweets (200 is the maximum allowed count)\n",
    "    new_tweets = api.user_timeline(screen_name = username,count=199)\n",
    "\n",
    "    alltweets.extend(new_tweets)\n",
    "\n",
    "    # save the id of the oldest tweet less one\n",
    "    # makes sure we keep fetching older tweets as we loop through rather than fetching same tweets \n",
    "    oldest = alltweets[-1].id - 1\n",
    "\n",
    "    # Stay in the loop as long as new tweets are available to fetch  \n",
    "    while len(new_tweets) > 0:\n",
    "\n",
    "        new_tweets = api.user_timeline(screen_name = username,count=199,max_id=oldest)\n",
    "        alltweets.extend(new_tweets)\n",
    "        oldest = alltweets[-1].id - 1\n",
    "\n",
    "\n",
    "        print(\"Total tweets downloaded from %s are %s\" % (username,len(alltweets)))\n",
    "    return alltweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tweets downloaded from midasIIITD are 346\n",
      "Total tweets downloaded from midasIIITD are 346\n",
      "346\n"
     ]
    }
   ],
   "source": [
    "data = get_tweetss('midasIIITD', api)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def store_tweets(alltweets):\n",
    "  \n",
    "    tweet_list=[] # a list of all formatted tweets\n",
    "\n",
    "    #looping through all the tweets in the list\n",
    "    for tweet in alltweets:\n",
    "        l = []\n",
    "        tweet_information=dict() # a dict to contain information about single tweet\n",
    "\n",
    "    # code to check for images present in tweet\n",
    "    for image in  tweet.entities.get('media', []): # returns an empty list if no image is present\n",
    "        l = image['media_url'] # return a list of image url\n",
    "    if(len(l)>0):\n",
    "        tweet_information['image_count'] = len(l)\n",
    "    else:\n",
    "        tweet_information['image_count'] = None\n",
    "\n",
    "    # text of tweet                \n",
    "    tweet_information['text']=tweet.text\n",
    "    #date and time of tweet\n",
    "    tweet_information['created_at']=tweet.created_at.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    # id of this tweet\n",
    "    tweet_information['id_str']=tweet.id_str\n",
    "    # retweet count\n",
    "    tweet_information['retweet_count']=tweet.retweet_count\n",
    "\n",
    "    #favourites count\n",
    "    tweet_information['favorite_count']=tweet.favorite_count\n",
    "    #username of the user to which it was replied (is Nullable)\n",
    "    tweet_information['in_reply_to_screen_name']=tweet.in_reply_to_screen_name\n",
    "\n",
    "    # user information in user dictionery\n",
    "    user_dictionery=tweet._json['user']\n",
    "    # no of followers of the user\n",
    "    tweet_information['followers_count']=user_dictionery['followers_count']\n",
    "    # screename of the person who tweeted this\n",
    "    tweet_information['screen_name']=user_dictionery['screen_name']\n",
    "\n",
    "\n",
    "    # add this tweet to the dictionary\n",
    "    tweet_list.append(tweet_information)\n",
    "\n",
    "    with jsonlines.open('/Users/amo/Desktop/twitter.jsonl', mode='w') as writer:\n",
    "        writer.write(tweet_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "import pandas as pd\n",
    "import json\n",
    "store_tweets(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/amo/Desktop/twitter.jsonl\") as datafile:\n",
    "    data = json.load(datafile)\n",
    "dataframe = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataframe[['created_at', 'text', 'favorite_count', 'retweet_count', 'image_count']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            created_at                                               text  \\\n",
      "0  2018-07-23 12:53:15  MIDAS is a group of researchers at IIIT-Delhi ...   \n",
      "\n",
      "   favorite_count  retweet_count image_count  \n",
      "0               7              4        None  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets =api.user_timeline(screen_name='midasIIITD')\n",
    "\n",
    "#attributes\n",
    "tweet_text = []\n",
    "tweet_time = []\n",
    "tweet_fav_count = []\n",
    "tweet_retweet_count = []\n",
    "tweet_img_count = []\n",
    "final = []\n",
    "\n",
    "#Going through all tweets and appending them in a dict and appending the dict to a list\n",
    "\n",
    "for index, tweet in enumerate(tweets):\n",
    "    tweet_text.append(tweet.text)\n",
    "    tweet_time.append(tweet.created_at)\n",
    "    tweet_retweet_count.append(tweet.retweet_count)\n",
    "    tweet_fav_count.append(tweet.favorite_count)\n",
    "    media = tweet.entities.get('media', [])\n",
    "    count = 0 \n",
    "    for med in media:\n",
    "        count += 1\n",
    "    if count == 0:\n",
    "        tweet_img_count.append(\"NULL\")\n",
    "    else:\n",
    "        tweet_img_count.append(count)\n",
    "    output = {\n",
    "    \"text\":tweet_text[index],\n",
    "    \"time\":tweet_time[index],\n",
    "    \"fav_count\":tweet_retweet_count[index],\n",
    "    \"retweet_count\":tweet_retweet_count[index],\n",
    "    \"img_count\":tweet_img_count[index]\n",
    "    }\n",
    "    final.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dumping the file\n",
    "\n",
    "import json\n",
    "with open('result.json', 'w') as f:\n",
    "    f.write(json.dumps(final,default=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
